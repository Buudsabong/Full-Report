@article{birdclef,
	title = {{BirdCLEF} 2020 {\textbar} {ImageCLEF} / {LifeCLEF} - {Multimedia} {Retrieval} in {CLEF}},
	url = {https://www.imageclef.org/BirdCLEF2020},
	urldate = {2020-03-04},
}

@article{xeno-canto,
	title = {Xeno-canto {Foundation} and {Naturalis} {Biodiversity} {Center} (2020)},
	url = {https://www.xeno-canto.org/about/xeno-canto},
	urldate = {2020-05-10},
}

@article{Kahl2019,
abstract = {The BirdCLEF challenge-as part of the 2019 LifeCLEF Lab [7]-offers a large-scale proving ground for system-oriented evaluation of bird species identification based on audio recordings. The challenge uses data collected through Xeno-canto, the worldwide community of bird sound recordists. This ensures that BirdCLEF is close to the conditions of real-world application, in particular with regard to the number of species in the training set (659). In 2019, the challenge was focused on the difficult task of recognizing all birds vocalizing in omni-directional soundscape recordings. Therefore, the dataset of the previous year was extended with more than 350 hours of manually annotated soundscapes that were recorded using 30 field recorders in Ithaca (NY, USA). This paper describes the methodology of the conducted evaluation as well as the synthesis of the main results and lessons learned.},
author = {Kahl, Stefan and St{\"{o}}ter, Fabian Robert and Go{\"{e}}au, Herv{\'{e}} and Glotin, Herv{\'{e}} and Planqu{\'{e}}, Robert and Vellinga, Willem Pier and Joly, Alexis},
booktitle = {CEUR Workshop Proceedings},
issn = {16130073},
keywords = {Audio,Benchmark,Bioacoustics,Bird,Call,Collection,Ecological monitoring,Evaluation,Fine-grained classification,Identification,LifeCLEF,Retrieval,Song,Species},
title = {{Overview of BIRDCLEF 2019: Large-scale bird recognition in soundscapes}},
year = {2019}
}

@article{birdgenie,
	title = {{BirdGenie} {Homepage} (2020)},
	url = {http://www.birdgenie.com/},
	abstract = {ID Birds by Song},
	language = {en-US},
	urldate = {2020-05-10},
	journal = {BirdGenie},
}

@article{JiaDeng2009,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called {\&}{\#}x201C;ImageNet{\&}{\#}x201D;, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {{Jia Deng} and {Wei Dong} and Socher, R. and {Li-Jia Li} and {Kai Li} and {Li Fei-Fei}},
doi = {10.1109/cvprw.2009.5206848},
title = {{ImageNet: A large-scale hierarchical image database}},
year = {2009}
}

@article{Pfeiffer1987,
abstract = {A programming language is presented in which has the feature that$\backslash$nfirst and second order partial derivatives of a function can be calculated$\backslash$nusing differentiation arithmetic. The language syntax allows the$\backslash$nuser to specify which variables each function is required to be differentiated$\backslash$nwith respect to. Model examples are provided.},
author = {Pfeiffer, F W},
issn = {01635778},
journal = {ACM SIGNUM Newsletter},
title = {{Automatic differentiation in PyTorch Adam}},
year = {1987}
}

@article{mcfee_librosa/librosa:_2020,
	title = {librosa/librosa: 0.7.2},
	copyright = {Open Access},
	shorttitle = {librosa/librosa},
	url = {https://zenodo.org/record/3606573},
	abstract = {This is primarily a bug-fix release, and most likely the last release in the 0.7 series. It includes fixes for errors in dynamic time warping (DTW) and RMS energy calculation, and several corrections to the documentation. Inverse-liftering is now supported in MFCC inversion, and an implementation of mu-law companding has been added. Please refer to the documentation for a full list of changes.},
	urldate = {2020-01-13},
	publisher = {Zenodo},
	author = {McFee, Brian and Lostanlen, Vincent and McVicar, Matt and Metsai, Alexandros and Balke, Stefan and Thomé, Carl and Raffel, Colin and Malek, Ayoub and Lee, Dana and Zalkow, Frank and {Kyungyun Lee} and Nieto, Oriol and Mason, Jack and Ellis, Dan and Yamamoto, Ryuichi and Seyfarth, Scott and Battenberg, Eric and {Виктор Морозов} and Bittner, Rachel and {Keunwoo Choi} and Moore, Josh and {Ziyao Wei} and Hidaka, Shunsuke and {Nullmightybofo} and Friesch, Pius and {Fabian-Robert Stöter} and Hereñú, Darío and {Taewoon Kim} and Vollrath, Matt and Weiss, Adam},
	month = jan,
	year = {2020},
	doi = {10.5281/ZENODO.3606573},
}


@article{Imbalanced_dealing_medium, 
  title = {Dealing with Imbalanced Classes in Machine Learning}, 
  author = {Devin Soni}, 
  year = {2019},
  url = {https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2}

}

@article{AT1987,
   title = {มาทำความรู้จัก รูปแบบสัญญาณเสียง Digital แบบ PCM กันเถอะ (ฉบับปรับปรุง) | RE.V –>},
   url = {https://rev.at1987.com/articles/pulse-code-modulation/},
}
 
@article{international_evalmetric,
abstract = {Evaluation metric plays a critical role in achieving the optimal classifier during the classification training. Thus, a selection of suitable evaluation metric is an important key for discriminating and obtaining the optimal classifier. This paper systematically reviewed the related evaluation metrics that are specifically designed as a discriminator for optimizing generative classifier. Generally, many generative classifiers employ accuracy as a measure to discriminate the optimal solution during the classification training. However, the accuracy has several weaknesses which are less distinctiveness, less discriminability, less informativeness and bias to majority class data. This paper also briefly discusses other metrics that are specifically designed for discriminating the optimal solution. The shortcomings of these alternative metrics are also discussed. Finally, this paper suggests five important aspects that must be taken into consideration in constructing a new discriminator metric. metric},
author = {M, Hossin and M.N, Sulaiman},
doi = {10.5121/ijdkp.2015.5201},
issn = {2231007X},
journal = {International Journal of Data Mining {\&} Knowledge Management Process},
title = {{A Review on Evaluation Metrics for Data Classification Evaluations}},
year = {2015}
}

----refCh.3------
@article{Goeau2018,
abstract = {The BirdCLEF challenge offers a large-scale proving ground for system-oriented evaluation of bird species identification based on audio recordings of their sounds. One of its strengths is that it uses data collected through Xeno-canto, the worldwide community of bird sound recordists. This ensures that BirdCLEF is close to the conditions of real-world application, in particular with regard to the number of species in the training set (1500). Two main scenarios are evaluated: (i) the identification of a particular bird species in a recording, and (ii), the recognition of all species vocalising in a long sequence (up to one hour) of raw sound-scapes that can contain tens of birds singing more or less simultaneously. This paper reports an overview of the systems developed by the six participating research groups, the methodology of the evaluation of their performance, and an analysis and discussion of the results obtained.},
author = {Go{\"{e}}au, Herv{\'{e}} and Kahl, Stefan and Glotin, Herv{\'{e}} and Planqu{\'{e}}, Robert and Vellinga, Willem Pier and Joly, Alexis},
booktitle = {CEUR Workshop Proceedings},
issn = {16130073},
keywords = {Audio,Benchmark,Bioacoustics,Bird,Call,Collection,Ecological monitoring,Evaluation,Fine-grained classification,Identification,LifeCLEF,Retrieval,Song,Species},
title = {{Overview of BirdCLEF 2018: Monospecies vs. soundscape bird identification}},
year = {2018}
}

@article{EarthSky,
title = {{Why do birds sing? | Earth | EarthSky}},
url = {https://earthsky.org/earth/why-do-birds-sing},
urldate = {2020-05-10}
}

@article{Yoon2009,
abstract = {Hidden Markov models (HMMs) have been extensively used in biological sequence analysis. In this paper, we give a tutorial review of HMMs and their applications in a variety of problems in molecular biology. We especially focus on three types of HMMs: the profile-HMMs, pair-HMMs, and context-sensitive HMMs. We show how these HMMs can be used to solve various sequence analysis problems, such as pairwise and multiple sequence alignments, gene annotation, classification, similarity search, and many others.},
author = {Yoon, Byung-Jun},
doi = {10.2174/138920209789177575},
issn = {13892029},
journal = {Current Genomics},
title = {{Hidden Markov Models and their Applications in Biological Sequence Analysis}},
year = {2009}
}

@article{Birdingbyear,
title = {{Identify Bird Calls - Easy Tips for Birding by Ear}},
url = {https://www.thespruce.com/birding-by-ear-basics-387331},
urldate = {2020-05-10}
}



%%% ------------------------------------------------------- %%%

@article{abadiTensorFlowLargeScaleMachine2016,
  author = {Abadi, Mart{\'i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  title = {{{TensorFlow}}: {{Large}}-{{Scale Machine Learning}} on {{Heterogeneous Distributed Systems}}},
  year = {2016},
  eprinttype = {arxiv},
  eprint = {1603.04467},
  primaryClass = {cs},
  urldate = {2019-12-16},
  archivePrefix = {arXiv},
  journal = {arXiv:1603.04467 [cs]},
  url = {http://arxiv.org/abs/1603.04467}
}

@inproceedings{aninaOuluVS2MultiviewAudiovisual2015,
  author = {Anina, Iryna and {Ziheng Zhou} and {Guoying Zhao} and Pietikainen, Matti},
  title = {{{OuluVS2}}: {{A}} Multi-View Audiovisual Database for Non-Rigid Mouth Motion Analysis},
  publisher = {{IEEE}},
  year = {2015},
  address = {{Ljubljana}},
  isbn = {978-1-4799-6026-2},
  doi = {10.1109/FG.2015.7163155},
  booktitle = {2015 11th {{IEEE International Conference}} and {{Workshops}} on {{Automatic Face}} and {{Gesture Recognition}} ({{FG}})},
  urldate = {2019-10-26},
  pages = {1--5},
  url = {http://ieeexplore.ieee.org/document/7163155/}
}

@article{assaelLipNetEndtoEndSentencelevel2016,
  author = {Assael, Yannis M. and Shillingford, Brendan and Whiteson, Shimon and {de Freitas}, Nando},
  title = {{{LipNet}}: {{End}}-to-{{End Sentence}}-Level {{Lipreading}}},
  year = {2016},
  eprinttype = {arxiv},
  eprint = {1611.01599},
  primaryClass = {cs},
  urldate = {2019-10-05},
  archivePrefix = {arXiv},
  journal = {arXiv:1611.01599 [cs]},
  url = {http://arxiv.org/abs/1611.01599}
}

@article{bhardwajEfficientVideoClassification2019,
  author = {Bhardwaj, Shweta and Srinivasan, Mukundhan and Khapra, Mitesh M.},
  title = {Efficient {{Video Classification Using Fewer Frames}}},
  year = {2019},
  eprinttype = {arxiv},
  eprint = {1902.10640},
  primaryClass = {cs},
  urldate = {2019-10-15},
  archivePrefix = {arXiv},
  journal = {arXiv:1902.10640 [cs]},
  url = {http://arxiv.org/abs/1902.10640}
}

@misc{burtWebVideoPhotos2019,
  author = {Burt, Chris},
  title = {Web Video, Photos, or Siblings Can Spoof {{Samsung Galaxy S10}} Facial Recognition},
  year = {2019},
  journal = {Web video, photos, or siblings can spoof Samsung Galaxy S10 facial recognition},
  url = {https://www.biometricupdate.com/201903/web-video-photos-or-siblings-can-spoof-samsung-galaxy-s10-facial-recognition}
}

@article{cholletXceptionDeepLearning2017,
  author = {Chollet, Fran{\c c}ois},
  title = {Xception: {{Deep Learning}} with {{Depthwise Separable Convolutions}}},
  year = {2017},
  eprinttype = {arxiv},
  eprint = {1610.02357},
  primaryClass = {cs},
  urldate = {2020-05-06},
  archivePrefix = {arXiv},
  journal = {arXiv:1610.02357 [cs]},
  url = {http://arxiv.org/abs/1610.02357}
}

@article{chungEmpiricalEvaluationGated2014,
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  year = {2014},
  eprinttype = {arxiv},
  eprint = {1412.3555},
  primaryClass = {cs},
  urldate = {2019-12-20},
  archivePrefix = {arXiv},
  journal = {arXiv:1412.3555 [cs]},
  url = {http://arxiv.org/abs/1412.3555}
}

@misc{davisMasterFingerprintsCan2017,
  author = {Davis, Russel},
  title = {``{{Master}}'' Fingerprints Can Unlock Almost Any Phone, Bypassing Fingerprint Security in Seconds},
  year = {2017},
  journal = {``Master'' fingerprints can unlock almost any phone, bypassing fingerprint security in seconds},
  url = {https://newstarget.com/2017-05-02-master-fingerprints-can-unlock-almost-any-phone-bypassing-fingerprint-security-in-seconds.html}
}

@article{dengArcFaceAdditiveAngular2018,
  author = {Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  title = {{{ArcFace}}: {{Additive Angular Margin Loss}} for {{Deep Face Recognition}}},
  year = {2018},
  eprinttype = {arxiv},
  eprint = {1801.07698},
  primaryClass = {cs},
  urldate = {2019-10-05},
  archivePrefix = {arXiv},
  journal = {arXiv:1801.07698 [cs]},
  url = {http://arxiv.org/abs/1801.07698}
}

@article{fernandez-lopezSurveyAutomaticLipreading2018,
  author = {{Fernandez-Lopez}, Adriana and Sukno, Federico M.},
  title = {Survey on Automatic Lip-Reading in the Era of Deep Learning},
  year = {2018},
  doi = {10.1016/j.imavis.2018.07.002},
  urldate = {2019-10-05},
  journal = {Image and Vision Computing},
  pages = {53--72},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885618301276}
}

@inproceedings{fungEndToEndLowResourceLipReading2018,
  author = {Fung, Ivan and Mak, Brian},
  title = {End-{{To}}-{{End Low}}-{{Resource Lip}}-{{Reading}} with {{Maxout Cnn}} and {{Lstm}}},
  publisher = {{IEEE}},
  year = {2018},
  address = {{Calgary, AB}},
  isbn = {978-1-5386-4658-8},
  doi = {10.1109/ICASSP.2018.8462280},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  urldate = {2019-10-05},
  pages = {2511--2515},
  url = {https://ieeexplore.ieee.org/document/8462280/}
}

@article{hermansDefenseTripletLoss2017,
  author = {Hermans, Alexander and Beyer, Lucas and Leibe, Bastian},
  title = {In {{Defense}} of the {{Triplet Loss}} for {{Person Re}}-{{Identification}}},
  year = {2017},
  eprinttype = {arxiv},
  eprint = {1703.07737},
  primaryClass = {cs},
  urldate = {2019-10-05},
  archivePrefix = {arXiv},
  journal = {arXiv:1703.07737 [cs]},
  url = {http://arxiv.org/abs/1703.07737}
}

@article{hochreiterLongShortTermMemory1997,
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  title = {Long {{Short}}-{{Term Memory}}},
  year = {1997},
  doi = {10.1162/neco.1997.9.8.1735},
  urldate = {2020-05-08},
  journal = {Neural Computation},
  pages = {1735--1780},
  url = {http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735}
}

@article{jainIntroductionBiometricRecognition2004,
  author = {Jain, A.K. and Ross, A. and Prabhakar, S.},
  title = {An {{Introduction}} to {{Biometric Recognition}}},
  year = {2004},
  doi = {10.1109/TCSVT.2003.818349},
  urldate = {2019-10-25},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  pages = {4--20},
  url = {http://ieeexplore.ieee.org/document/1262027/}
}

@inproceedings{kazemiOneMillisecondFace2014,
  author = {Kazemi, Vahid and Sullivan, Josephine},
  title = {One Millisecond Face Alignment with an Ensemble of Regression Trees},
  publisher = {{IEEE}},
  year = {2014},
  address = {{Columbus, OH}},
  isbn = {978-1-4799-5118-5},
  doi = {10.1109/CVPR.2014.241},
  booktitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  urldate = {2019-10-06},
  pages = {1867--1874},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909637}
}

@article{kingDlibmlMachineLearning2009,
  author = {King, Davis E},
  title = {Dlib-Ml: {{A Machine Learning Toolkit}}},
  year = {2009},
  doi = {10.1145/1577069.1755843},
  pages = {4}
}

@article{laiVisualSpeakerIdentification2016,
  author = {Lai, Jun-Yao and Wang, Shi-Lin and Liew, Alan Wee-Chung and Shi, Xing-Jian},
  title = {Visual Speaker Identification and Authentication by Joint Spatiotemporal Sparse Coding and Hierarchical Pooling},
  year = {2016},
  doi = {10.1016/j.ins.2016.09.015},
  urldate = {2019-10-05},
  journal = {Information Sciences},
  pages = {219--232},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025516307599}
}

@inproceedings{liao3DConvolutionalNeural2018,
  author = {Liao, Jianguo and Wang, Shilin and Zhang, Xingxuan and Liu, Gongshen},
  title = {{{3D Convolutional Neural Networks Based Speaker Identification}} and {{Authentication}}},
  publisher = {{IEEE}},
  year = {2018},
  address = {{Athens}},
  isbn = {978-1-4799-7061-2},
  doi = {10.1109/ICIP.2018.8451204},
  booktitle = {2018 25th {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  urldate = {2019-10-05},
  pages = {2042--2046},
  url = {https://ieeexplore.ieee.org/document/8451204/}
}

@article{liuLearningMultiBoostedHMMs2014,
  author = {Liu, Xin and Cheung, Yiu-ming},
  title = {Learning {{Multi}}-{{Boosted HMMs}} for {{Lip}}-{{Password Based Speaker Verification}}},
  year = {2014},
  doi = {10.1109/TIFS.2013.2293025},
  urldate = {2019-10-05},
  journal = {IEEE Transactions on Information Forensics and Security},
  pages = {233--246},
  url = {http://ieeexplore.ieee.org/document/6675773/}
}

@article{maitreXm2vtsdbExtendedM2vts2000,
  author = {Ma{\^i}tre, Gilbert and {Valais-Wallis}, HES-SO and Luettin, Juergen and GmbH, Robert Bosch},
  title = {Xm2vtsdb: {{The}} Extended M2vts Database},
  year = {2000},
  pages = {7}
}

@inproceedings{mathulaprangsanSurveyVisualLip2015,
  author = {Mathulaprangsan, Seksan and Wang, Chien-Yao and Kusum, Aufaclav Zatu and Tai, Tzu-Chiang and Wang, Jia-Ching},
  title = {A Survey of Visual Lip Reading and Lip-Password Verification},
  publisher = {{IEEE}},
  year = {2015},
  address = {{Hong Kong, Hong Kong}},
  isbn = {978-1-4673-8237-3},
  doi = {10.1109/ICOT.2015.7498485},
  booktitle = {2015 {{International Conference}} on {{Orange Technologies}} ({{ICOT}})},
  urldate = {2019-10-05},
  pages = {22--25},
  url = {http://ieeexplore.ieee.org/document/7498485/}
}

@inproceedings{matsumotoImpactArtificialGummy2002,
  author = {Matsumoto, Tsutomu and Matsumoto, Hiroyuki and Yamada, Koji and Hoshino, Satoshi},
  title = {Impact of Artificial "Gummy" Fingers on Fingerprint Systems},
  year = {2002},
  address = {{San Jose, CA}},
  doi = {10.1117/12.462719},
  urldate = {2019-10-07},
  booktitle = {Electronic {{Imaging}} 2002},
  pages = {275--289},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=878135}
}

@article{mcquillanLipreadingSecretSecurity2019,
  author = {McQuillan, Liam},
  title = {Is Lip-Reading the Secret to Security?},
  year = {2019},
  doi = {10.1016/S0969-4765(19)30085-2},
  urldate = {2019-10-07},
  journal = {Biometric Technology Today},
  pages = {5--7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0969476519300852}
}

@article{micikeviciusMixedPrecisionTraining2018,
  author = {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  title = {Mixed {{Precision Training}}},
  year = {2018},
  eprinttype = {arxiv},
  eprint = {1710.03740},
  primaryClass = {cs, stat},
  urldate = {2020-05-08},
  archivePrefix = {arXiv},
  journal = {arXiv:1710.03740 [cs, stat]},
  url = {http://arxiv.org/abs/1710.03740}
}

@article{mishuVulnerabilitiesFingerprintAuthentication2018,
  author = {Mishu, Tanjarul Islam and Rahman, Md. Mijanur},
  title = {Vulnerabilities of {{Fingerprint Authentication Systems}} and {{Their Securities}}},
  year = {2018},
  journal = {International Journal of Computer Science and Information Security,}
}

@misc{nvidiaTensorFlowDeterminism,
  author = {NVIDIA},
  title = {{{TensorFlow Determinism}}},
  url = {https://github.com/NVIDIA/tensorflow-determinism}
}

@article{ortega-garciaAuthenticationGetsPersonal2004,
  author = {{Ortega-Garcia}, J. and Bigun, J. and Reynolds, D. and {Gonzalez-Rodriguez}, J.},
  title = {Authentication Gets Personal with Biometrics},
  year = {2004},
  doi = {10.1109/MSP.2004.1276113},
  urldate = {2019-10-07},
  journal = {IEEE Signal Processing Magazine},
  pages = {50--62},
  url = {http://ieeexplore.ieee.org/document/1276113/}
}

@article{petridisVisualOnlyRecognitionNormal2018,
  author = {Petridis, Stavros and Shen, Jie and Cetin, Doruk and Pantic, Maja},
  title = {Visual-{{Only Recognition}} of {{Normal}}, {{Whispered}} and {{Silent Speech}}},
  year = {2018},
  eprinttype = {arxiv},
  eprint = {1802.06399},
  primaryClass = {cs},
  urldate = {2019-10-05},
  archivePrefix = {arXiv},
  journal = {arXiv:1802.06399 [cs]},
  url = {http://arxiv.org/abs/1802.06399}
}

@article{qiuLearningSpatioTemporalRepresentation2017,
  author = {Qiu, Zhaofan and Yao, Ting and Mei, Tao},
  title = {Learning {{Spatio}}-{{Temporal Representation}} with {{Pseudo}}-{{3D Residual Networks}}},
  year = {2017},
  eprinttype = {arxiv},
  eprint = {1711.10305},
  primaryClass = {cs},
  urldate = {2020-05-06},
  archivePrefix = {arXiv},
  journal = {arXiv:1711.10305 [cs]},
  url = {http://arxiv.org/abs/1711.10305}
}

@incollection{sadoukCNNApproachesTime2018,
  author = {Sadouk, Lamyaa},
  title = {{{CNN Approaches}} for {{Time Series}} Classification},
  publisher = {{IntechOpen}},
  year = {2018},
  doi = {10.5772/intechopen.81170},
  urldate = {2019-10-05},
  booktitle = {Time {{Series Analysis}} [{{Working Title}}]},
  url = {https://www.intechopen.com/online-first/cnn-approaches-for-time-series-classification}
}

@inproceedings{sagonas300FacesIntheWild2013,
  author = {Sagonas, Christos and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
  title = {300 {{Faces}} In-the-{{Wild Challenge}}: {{The First Facial Landmark Localization Challenge}}},
  publisher = {{IEEE}},
  year = {2013},
  address = {{Sydney, Australia}},
  isbn = {978-1-4799-3022-7},
  doi = {10.1109/ICCVW.2013.59},
  booktitle = {2013 {{IEEE International Conference}} on {{Computer Vision Workshops}}},
  urldate = {2019-10-06},
  pages = {397--403},
  url = {http://ieeexplore.ieee.org/document/6755925/}
}

@article{sagonas300FacesInTheWild2016,
  author = {Sagonas, Christos and Antonakos, Epameinondas and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
  title = {300 {{Faces In}}-{{The}}-{{Wild Challenge}}: Database and Results},
  year = {2016},
  doi = {10.1016/j.imavis.2016.01.002},
  urldate = {2019-10-06},
  journal = {Image and Vision Computing},
  pages = {3--18},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885616000147}
}

@inproceedings{sagonasSemiautomaticMethodologyFacial2013,
  author = {Sagonas, Christos and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
  title = {A {{Semi}}-Automatic {{Methodology}} for {{Facial Landmark Annotation}}},
  publisher = {{IEEE}},
  year = {2013},
  address = {{OR, USA}},
  isbn = {978-0-7695-4990-3},
  doi = {10.1109/CVPRW.2013.132},
  booktitle = {2013 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}}},
  urldate = {2019-10-06},
  pages = {896--903},
  url = {http://ieeexplore.ieee.org/document/6595977/}
}

@article{schroffFaceNetUnifiedEmbedding2015,
  author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  title = {{{FaceNet}}: {{A Unified Embedding}} for {{Face Recognition}} and {{Clustering}}},
  year = {2015},
  doi = {10.1109/CVPR.2015.7298682},
  eprinttype = {arxiv},
  eprint = {1503.03832},
  urldate = {2019-12-02},
  archivePrefix = {arXiv},
  journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {815--823},
  url = {http://arxiv.org/abs/1503.03832}
}

@article{schusterBidirectionalRecurrentNeural1997,
  author = {Schuster, M. and Paliwal, K.K.},
  title = {Bidirectional Recurrent Neural Networks},
  year = {Nov./1997},
  doi = {10.1109/78.650093},
  urldate = {2020-05-09},
  journal = {IEEE Transactions on Signal Processing},
  pages = {2673--2681},
  url = {http://ieeexplore.ieee.org/document/650093/}
}

@inproceedings{shiVisualSpeakerAuthentication2016,
  author = {Shi, Xiao-Xing and Wang, Shi-Lin and Lai, Jun-Yao},
  title = {Visual Speaker Authentication by Ensemble Learning over Static and Dynamic Lip Details},
  publisher = {{IEEE}},
  year = {2016},
  address = {{Phoenix, AZ, USA}},
  isbn = {978-1-4673-9961-6},
  doi = {10.1109/ICIP.2016.7533099},
  booktitle = {2016 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  urldate = {2019-10-05},
  pages = {3942--3946},
  url = {http://ieeexplore.ieee.org/document/7533099/}
}

@article{sunHumanActionRecognition2015,
  author = {Sun, Lin and Jia, Kui and Yeung, Dit-Yan and Shi, Bertram E.},
  title = {Human {{Action Recognition}} Using {{Factorized Spatio}}-{{Temporal Convolutional Networks}}},
  year = {2015},
  eprinttype = {arxiv},
  eprint = {1510.00562},
  primaryClass = {cs},
  urldate = {2020-05-06},
  archivePrefix = {arXiv},
  journal = {arXiv:1510.00562 [cs]},
  url = {http://arxiv.org/abs/1510.00562}
}

@article{tranCloserLookSpatiotemporal2017,
  author = {Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  title = {A {{Closer Look}} at {{Spatiotemporal Convolutions}} for {{Action Recognition}}},
  year = {2017},
  eprinttype = {arxiv},
  eprint = {1711.11248},
  primaryClass = {cs},
  urldate = {2019-10-10},
  archivePrefix = {arXiv},
  journal = {arXiv:1711.11248 [cs]},
  url = {http://arxiv.org/abs/1711.11248}
}

@article{wangDeepFaceRecognition2018,
  author = {Wang, Mei and Deng, Weihong},
  title = {Deep {{Face Recognition}}: {{A Survey}}},
  year = {2018},
  eprinttype = {arxiv},
  eprint = {1804.06655},
  primaryClass = {cs},
  urldate = {2019-10-05},
  archivePrefix = {arXiv},
  journal = {arXiv:1804.06655 [cs]},
  url = {http://arxiv.org/abs/1804.06655}
}

@inproceedings{xiaogangwangBoostedMultitaskLearning2009,
  author = {{Xiaogang Wang} and Zhang, Cha and Zhang, Zhengyou},
  title = {Boosted Multi-Task Learning for Face Verification with Applications to Web Image and Video Search},
  publisher = {{IEEE}},
  year = {2009},
  address = {{Miami, FL}},
  isbn = {978-1-4244-3992-8},
  doi = {10.1109/CVPR.2009.5206736},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  urldate = {2019-10-08},
  pages = {142--149},
  url = {https://ieeexplore.ieee.org/document/5206736/}
}

@article{xieRethinkingSpatiotemporalFeature2018,
  author = {Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  title = {Rethinking {{Spatiotemporal Feature Learning}}: {{Speed}}-{{Accuracy Trade}}-Offs in {{Video Classification}}},
  year = {2018},
  eprinttype = {arxiv},
  eprint = {1712.04851},
  primaryClass = {cs},
  urldate = {2019-11-18},
  archivePrefix = {arXiv},
  journal = {arXiv:1712.04851 [cs]},
  url = {http://arxiv.org/abs/1712.04851}
}

@book{Goodfellow-et-al-2016,
  author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  title={Deep Learning},
  year={2016},
  publisher={MIT Press},
}
